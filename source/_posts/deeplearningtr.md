title: neuralnetworksanddeeplearning第六章翻译（1）
date: 2016-02-24 17:57:57
tags: "machine learning"
---
本篇文章是对http://neuralnetworksanddeeplearning.com/chap6.html的翻译。
# 正文
*　　在上一章，我们了解了深层神经网络比浅层神经网络更加难以训练，但是我们有理由相信，一旦我们训练出来了深度神经网络，它会比浅层神经网络更屌，虽然上一章的消息是令人沮丧的，但是我们不能因为它而停止脚步。在这章，我们会讲一种技术去训练深度神经网络，并将该技术用于实践。对于应用深度网络进行图像识别，语音识别和一些其他的应用，我们会做一个简要的回顾。我们也会简要的说说神经网络、人工智能等的未来。
*　　这章会很长，为了帮助你学的更好，让我们就像旅游一样对待吧。本节是仅有的松散耦合的一部分，所以如果你比较熟悉神经网络的话，可以跳着看一些你感兴趣的。
*　　这章的这部分主要是来介绍一种广泛应用的深度神经网络：deep convoluntional networks(卷积深度神经网络)，我们通过详细的代码来解释这一部分，代码是用卷积神经网络来解决手写数字识别的问题，数据是MNIST data。
![201602241](https://raw.githubusercontent.com/xsj4cs/xsj4cs.github.io/hexo/images/201602241.png)
我们从本书之前用来解决这个问题的浅层神经网络来开始我们的卷积神经网络。通过不断的迭代，我们将构建更屌的网络。随着我们的步伐，我们将探索许多强大的技术，比如：卷积，汇集（pooling），使用GPUs来使训练比训练浅层网络更加充分，算法性更强通过我们的训练数据（当然减少过拟合），对dropout技术的使用（也是用来减少过拟合），对整个网络的使用等等。这样就能形成一个系统，表现出近似人才有的行为。对10000个MNIST测试图片（图片在训练过程中不可见），我们的系统可以正确分类9967个，这里我们挑出了被错误分类的33个图片。图片中正确分类在右上，系统给出的分类在右下：
![201602242](https://raw.githubusercontent.com/xsj4cs/xsj4cs.github.io/hexo/images/201602242.png)
图片中许多例子即使是人类区分也是很容易分错的。举个例子，最上面那排的第3个图片，对我来说，看起来更像是9和不是8，这是人为的一个分类。我们的系统也人为他是一个9，我想这种错误至少是可以理解的吧，也许甚至应该值得表扬。我得出这个讨论结果是最近重大的一个调查表明，用神经网络（特别是卷积神经网络）来做图像识别是很好的。
*　　本章剩下的是讨论从一个广阔且少细节的东西中进行深度学习的穿透力。我们会简要说下像循环神经网络（RNN），LSTM（一种时间递归神经网络）等这些的神经网络模型的调查结果和是怎么把这些模型应用到诸如语音识别，自然语言处理等其他发面。而且我们将思考神经网络和机器学习的未来，像什么人们意图驱动的用户界面，神经网络在人工智能方面扮演的角色。
*　　本章放在后面几章之前，是为了整理和知道，像bp，正则化，softmax功能等等。但是，通过前面的一些章节的学习，相信看这章是不需要费很大劲的。如果费劲的话，请看章节一，神经网络的基础。如果我使用2-5章节中的概念，我会提供链接让你能在过去复习，如果有必要的话。
*　　不管这是否值得一提。这不是最新也不是最伟大的神经网络教程。我们也不会训练深层网络去解决非常前沿的问题。相反，我们的重点为了去理解深层神经网络背后的一些核心原则，并做一些简单的，容易理解的MNIST问题。用另外一种话说，本章不会带你去领略前沿的风采，而只是把目的基于基础面，所以我们要让你理解本书的作用范围。
　　本书目前还在测试阶段，我们欢迎通知错别字等错误。请在线回复mn@michaelnielsen.org。
# 吐槽
额，感觉这章没有什么翻译的必要。。。
